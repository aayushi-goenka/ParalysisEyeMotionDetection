Paralysis occurs when we are unable to make voluntary muscle movements. Every year, around the world, between 250,000 and 500,000 people suffer a spinal cord injury.

Learning to live with paralysis is challenging. It can cause dramatic changes to your life, activities and self-image. These changes can result in mental health issues and depression. 

A model by which we can help paralysed people to communicate their needs better with the world. Using the motion of their eyes, we are classifying whether they are looking towards their right or left and based on that, we are giving them 2 options for availing facilities like Medical Help or having Food, with the help of an API.

Collected 70% facial images from online resources like Bing API and websites which provide such datasets

Collected 30% facial images manually by taking pictures of known people such as friends and family with their written consent.
The link to the dataset is mentioned as : https://drive.google.com/drive/folders/1kn3D3V7EQvmIFsFfSPTBQj3WmK6HVUiT?usp=sharing

Thus, we have trained and tested our datasets on established models and compared their results.
The model has given better performance when it is trained on the eyes dataset compared to the facial dataset.
 We built our custom model and have successfully deployed it which classifies the eye movement from a live camera feed with 69.3% accuracy


https://user-images.githubusercontent.com/66373454/181106242-2ead020f-0302-460e-b0f3-299585b14b16.mp4

